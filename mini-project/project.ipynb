{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/leo/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /home/leo/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unidecode as un\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB_Dataset.csv')\n",
    "df_old = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "We also need to make sure that the sentiments are only positive or negative (in case of faults in data)\n",
    "\n",
    "We also need to remove HTML tags, due to the reviews being scraped from IMDB\n",
    "\n",
    "We start by removing special letters etc. with unicode. This will change é to e á to a etc. \n",
    "\n",
    "After this we remove all special characters and make the comments clean. \n",
    "\n",
    "Removing stopwords\n",
    "\n",
    "Lemmatizing the data\n",
    "\n",
    "Finally we also remove unnecessary spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63835/1069883621.py:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  df[\"review\"] = df[\"review\"].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n"
     ]
    }
   ],
   "source": [
    "# Remove if sentiment is not positive or negative\n",
    "mask = df['sentiment'].isin(['positive', 'negative'])\n",
    "df = df[mask]\n",
    "\n",
    "# Lablenize sentiment\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Remove html tags\n",
    "df[\"review\"] = df[\"review\"].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n",
    "\n",
    "# Fix decode and allowed_chars\n",
    "allowed_chars = \" abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "df[\"review\"] = df[\"review\"].apply(lambda x: un.unidecode(x).lower())\n",
    "df[\"review\"] = df[\"review\"].apply(lambda x: ''.join([i for i in x if i in allowed_chars]))\n",
    "\n",
    "# Remove stopwords\n",
    "stop = stopwords.words('english')\n",
    "df[\"review\"] = df[\"review\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "# Lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df[\"review\"] = df[\"review\"].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "\n",
    "# Strip unnecessary spaces\n",
    "df[\"review\"] = df[\"review\"].apply(lambda x: x.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data\n",
    "The data will be split into training and testing data as well as labels and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 40000\n",
    "train_data, train_labels = df['review'][:train_size], df['sentiment'][:train_size]\n",
    "test_data, test_labels = list(df['review'][train_size:]), list(df['sentiment'][train_size:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram\n",
    "Create ngram representation of each word in the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_train_reviews.shape = (40000, 7144506)\n",
      "cv_test_reviews.shape = (10000, 7144506)\n"
     ]
    }
   ],
   "source": [
    "# ngram\n",
    "c = CountVectorizer(min_df=0.0, max_df=1.0, binary=False, ngram_range=(1,3))\n",
    "cv_train_reviews = c.fit_transform(train_data)\n",
    "cv_test_reviews = c.transform(test_data)\n",
    "\n",
    "print(f\"{cv_train_reviews.shape = }\")\n",
    "print(f\"{cv_test_reviews.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "We start by using a regression model, this is imported from sklear, and does not need very much work or knowledge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty=\"l2\", max_iter=500, C=1, random_state=42)\n",
    "lr_bow = lr.fit(cv_train_reviews, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_Bow_predict = lr.predict(cv_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(answer:list , predicted:list):\n",
    "    \"\"\"\n",
    "    Compare each of the values in answer with predicted.\n",
    "    Returns the accuracy\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(predicted)):\n",
    "        if answer[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct/len(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8998\n"
     ]
    }
   ],
   "source": [
    "lr_bow_score = accuracy_score(test_labels, list(lr_Bow_predict))\n",
    "print(f\"Score: {lr_bow_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
